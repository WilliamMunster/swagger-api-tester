# Swagger API自动化测试框架 - 测试用例设计

## 测试概览

| 项目 | 内容 |
|------|------|
| 项目名称 | Swagger API自动化测试框架 |
| 技术栈 | Python 3.8+ |
| 测试范围 | API全面测试（正向、反向、边界、安全、性能等） |
| 兼容性 | Swagger 2.0、OpenAPI 3.0+ |
| 数据策略 | 混合模式（自动生成+手动配置） |

## 需求分析

### 核心需求

| 需求ID | 需求描述 | 优先级 | 来源 |
|--------|----------|--------|------|
| REQ-001 | 支持Swagger 2.0和OpenAPI 3.0+格式解析 | P0 | 用户明确要求 |
| REQ-002 | 支持JSON和YAML文件格式 | P0 | 用户明确要求 |
| REQ-003 | 自动遍历所有API端点 | P0 | 用户核心需求 |
| REQ-004 | 自动生成测试用例 | P0 | 用户核心需求 |
| REQ-005 | 支持正向、反向、边界值等全面测试 | P0 | 用户选择 |
| REQ-006 | 混合数据模式（自动生成+手动配置） | P0 | 用户选择 |
| REQ-007 | 生成HTML测试报告 | P0 | 用户选择 |
| REQ-008 | 支持常见认证方式（Bearer、API Key等） | P1 | API测试最佳实践 |
| REQ-009 | Schema验证（响应格式、数据类型） | P1 | API测试最佳实践 |
| REQ-010 | 支持并发测试 | P2 | 性能测试需求 |
| REQ-011 | 支持安全测试（注入、越权等） | P2 | 安全测试最佳实践 |

## 框架架构设计

### 核心模块

```
swagger_api_tester/
├── core/                      # 核心功能模块
│   ├── __init__.py
│   ├── parser.py             # Swagger/OpenAPI解析器
│   ├── test_generator.py     # 测试用例生成器
│   ├── data_generator.py     # 测试数据生成器
│   ├── executor.py           # 测试执行引擎
│   ├── validator.py          # 响应验证器
│   ├── auth.py               # 认证处理
│   └── reporter.py           # 测试报告生成器
├── config/                    # 配置文件
│   ├── default_config.yaml   # 默认配置
│   └── test_data.yaml        # 手动测试数据配置
├── examples/                  # 示例文件
│   ├── petstore_swagger.json # Swagger 2.0示例
│   └── petstore_openapi.yaml # OpenAPI 3.0示例
├── tests/                     # 单元测试
├── reports/                   # 测试报告输出目录
├── requirements.txt           # 依赖包
├── main.py                    # 主程序入口
└── README.md                  # 使用说明
```

### 模块职责

| 模块 | 职责 | 关联需求 |
|------|------|----------|
| parser.py | 解析Swagger/OpenAPI文件，提取API端点信息 | REQ-001, REQ-002, REQ-003 |
| test_generator.py | 根据API定义生成测试场景和用例 | REQ-004, REQ-005 |
| data_generator.py | 自动生成测试数据，支持手动覆盖 | REQ-006 |
| executor.py | 执行测试用例，支持并发 | REQ-010 |
| validator.py | 验证响应状态码、schema、业务规则 | REQ-009 |
| auth.py | 处理各种认证方式 | REQ-008 |
| reporter.py | 生成HTML测试报告 | REQ-007 |

## 测试场景设计

### 场景分类

基于test-case-design skill的方法论，我们将API测试分为以下场景：

#### 1. 正向测试（P0）

| 场景ID | 场景描述 | 测试要点 | 关联需求 |
|--------|----------|----------|----------|
| POS-001 | 正常GET请求 | 有效参数，返回200，schema验证 | REQ-004, REQ-009 |
| POS-002 | 正常POST请求 | 有效请求体，返回201，schema验证 | REQ-004, REQ-009 |
| POS-003 | 正常PUT请求 | 有效更新数据，返回200，schema验证 | REQ-004, REQ-009 |
| POS-004 | 正常DELETE请求 | 删除成功，返回204或200 | REQ-004 |
| POS-005 | 带认证的请求 | 有效token，请求成功 | REQ-008 |

#### 2. 反向测试（P1）

| 场景ID | 场景描述 | 测试要点 | 关联需求 |
|--------|----------|----------|----------|
| NEG-001 | 缺少必填参数 | 返回400，错误信息明确 | REQ-005 |
| NEG-002 | 参数类型错误 | 返回400，类型校验生效 | REQ-005 |
| NEG-003 | 无效认证 | 返回401，拒绝访问 | REQ-008 |
| NEG-004 | 资源不存在 | 返回404，错误信息清晰 | REQ-005 |
| NEG-005 | 超出权限 | 返回403，权限控制生效 | REQ-011 (隐含) |

#### 3. 边界值测试（P1）

| 场景ID | 场景描述 | 测试要点 | 关联需求 |
|--------|----------|----------|----------|
| BND-001 | 字符串长度边界 | 最小值、最大值、超长 | REQ-005 |
| BND-002 | 数值范围边界 | 最小值、最大值、越界 | REQ-005 |
| BND-003 | 数组元素数量边界 | 空数组、最大数量、超量 | REQ-005 |
| BND-004 | 特殊字符处理 | SQL注入字符、XSS字符等 | REQ-011 |

#### 4. Schema验证测试（P0）

| 场景ID | 场景描述 | 测试要点 | 关联需求 |
|--------|----------|----------|----------|
| SCH-001 | 响应字段完整性 | 必填字段都存在 | REQ-009 |
| SCH-002 | 数据类型验证 | 字段类型符合定义 | REQ-009 |
| SCH-003 | 枚举值验证 | 枚举字段值在允许范围内 | REQ-009 |
| SCH-004 | 嵌套对象验证 | 复杂对象结构正确 | REQ-009 |

#### 5. 安全测试（P2）

| 场景ID | 场景描述 | 测试要点 | 关联需求 |
|--------|----------|----------|----------|
| SEC-001 | SQL注入防护 | 恶意SQL语句被拦截 | REQ-011 |
| SEC-002 | XSS攻击防护 | 恶意脚本被过滤 | REQ-011 |
| SEC-003 | 越权访问测试 | 不能访问他人数据 | REQ-011 |
| SEC-004 | 敏感信息泄露 | 错误信息不含敏感数据 | [最佳实践] |

#### 6. 性能测试（P2）

| 场景ID | 场景描述 | 测试要点 | 关联需求 |
|--------|----------|----------|----------|
| PERF-001 | 响应时间验证 | 接口响应时间<3s | [最佳实践] |
| PERF-002 | 并发测试 | 支持10并发无错误 | REQ-010 |
| PERF-003 | 大数据量测试 | 能处理大响应体 | [最佳实践] |

## 测试用例生成策略

### 自动生成规则

对每个API端点自动生成以下测试用例：

1. **正向用例** (1个)
   - 使用schema定义自动生成有效数据
   - 验证状态码和响应schema

2. **必填参数验证** (N个，N=必填参数数量)
   - 每个必填参数生成1个缺失测试用例
   - 验证返回400或422

3. **类型验证** (N个，N=参数数量)
   - 每个参数生成1个类型错误用例
   - 验证返回400

4. **边界值** (根据schema定义)
   - 字符串：空串、最大长度-1、最大长度、最大长度+1
   - 数值：最小值-1、最小值、最大值、最大值+1
   - 数组：空数组、单元素、最大元素

5. **认证测试** (如接口需要认证)
   - 无token、过期token、无效token

### 手动配置覆盖

通过 `config/test_data.yaml` 文件可以：
- 为特定接口提供真实业务数据
- 添加额外的测试场景
- 指定特殊的验证规则

示例：
```yaml
endpoints:
  - path: /api/users
    method: POST
    test_data:
      valid:
        username: "testuser"
        email: "test@example.com"
      invalid:
        - case: "invalid_email"
          data:
            username: "testuser"
            email: "not-an-email"
          expected_status: 400
```

## 测试报告设计

### HTML报告结构

```
测试报告
├── 概览
│   ├── 测试时间
│   ├── API基本信息
│   ├── 总用例数 / 通过 / 失败 / 跳过
│   └── 通过率
├── 按端点分组结果
│   ├── GET /api/users
│   │   ├── 正向测试: ✅
│   │   ├── 缺少参数: ✅
│   │   ├── 类型错误: ❌ (详细错误)
│   │   └── ...
│   └── POST /api/users
│       └── ...
├── 失败用例详情
│   ├── 请求信息
│   ├── 预期结果
│   ├── 实际结果
│   └── 差异对比
└── 统计图表
    ├── 通过率饼图
    └── 按优先级分布
```

## 需求反馈

基于API测试最佳实践，建议向需求方确认以下内容（如适用）：

| 序号 | 类型 | 问题描述 | 建议 | 参考来源 |
|------|------|----------|------|----------|
| 1 | 边界未定义 | Swagger中部分字段未定义maxLength/minimum等 | 补充边界值定义，便于自动化测试 | [最佳实践] |
| 2 | 错误码规范 | 是否有统一的错误码规范 | 定义错误码标准，便于验证 | [最佳实践] |
| 3 | 安全要求 | 是否需要进行安全测试 | 明确安全测试范围和标准 | [最佳实践] |
| 4 | 性能指标 | API响应时间的SLA要求 | 定义性能基线，便于回归测试 | [最佳实践] |
| 5 | 环境配置 | 测试环境的认证信息获取方式 | 提供测试环境配置文档 | 用户确认 |

## 质量检查清单

**需求可追溯性**：
- [x] 每个测试场景都有明确的需求来源
- [x] 无凭空假设的业务规则
- [x] 行业最佳实践已标注为[最佳实践]

**覆盖完整性**：
- [x] 覆盖所有HTTP方法（GET/POST/PUT/DELETE等）
- [x] 包含正向和反向测试
- [x] 包含边界值测试
- [x] 包含安全和性能测试

**可实现性**：
- [x] 技术方案清晰可行
- [x] 模块职责明确
- [x] 扩展性良好
